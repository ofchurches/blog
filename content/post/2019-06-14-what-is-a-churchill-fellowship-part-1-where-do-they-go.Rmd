---
title: What is a Churchill Fellowship Part 1 - Where do they go?
author: ''
date: '2019-06-14'
slug: what-is-a-churchill-fellowship-part-1-where-do-they-go
categories: []
tags:
  - maps
  - churchill fellowship
---

The [Churchill Fellowship](https://www.churchilltrust.com.au/) presents an amazing opportunity for Australians to:

>Travel overseas for 4-8 weeks to investigate inspiring practices around a topic or issue you are passionate about! Use the new knowledge and experience you gain from experts and specialists from around the world to make a difference in Australia.
>

I began thinking in earnest about applying for a fellowship in January 2018. But it was a bit overwhelming. I had so many questions. Chief amongst them where:

1) Where in the world *overseas* do fellows go?
2) What *topics or issues* do fellows study

But, as a statistician, I have a default pivot that I turn to that helps me deal with overwhelming stuff: I quantify it!

Wonderfully, the Churchill Fellowship maintains a comprehensive list of every fellowship going back to [Lois Wilksch's](https://www.churchilltrust.com.au/fellows/detail/45/Lois+WILKSCH%20%28Now%20Loffler%29) fellowship in 1966 to the UK which set out:

>"To study and extend knowledge of infant teaching and educational developments, particularly children's communication "
>

This resource of past fellowships is a great place to start thinking about what you could do as a fellow yourself. And with a bit of help from the `rvest` package we can get lots of information out of these pages to help understand what previous fellows have done.

So, this post is about my attempt to answer that first question: Where do fellows go?

This goes in a few stages:

1) Get the data
2) Clean the data
3) Visualise the data

First, load the packages

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(purrr)
library(rvest)
library(here)
library(knitr)
library(viridis)
library(readr)
library(broom)
library(ggrepel)
library(scales)
library(UpSetR)
```

With an inspection of the Churchill Fellowship [website](https://www.churchilltrust.com.au/fellows/) there are currently 218^[If anyone can suggest a neat way to find the number of pages without looking manually please let me know.] pages of felowship reports.

So, based on [this](https://stackoverflow.com/questions/36683510/r-web-scraping-across-multiple-pages) suggestion and the excellent `rvest` [tutorial](https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/) we can collect the data from each page.

The chunk below would actually work in `blogdown`! Seriously, you can do the scraping in the blog itself. Using `rvest::html` and `purr:map_df` makes it pretty efficient. But, each time I `blogdown::serve_site` on this blog it will pull the first 218 pages from the website. So these analyses would change over time. One day the Churchill Trust website might even change. So, I've downloaded the data available today and stored it in the "static" folder of this website as a ".csv" so you can play with it too.

```{r eval = FALSE}

url_base <- "https://www.churchilltrust.com.au/fellows/?page=%d"
n_pages <- 218

churchill_scrape <- map_df(1:n_pages, function(i) {
  
  page <- read_html(sprintf(url_base, i))
  
  tibble(project = html_text(html_nodes(page, ".year+ td")), 
         year = html_text(html_nodes(page, ".tbl-fellows .year")),
         fellow = html_text(html_nodes(page, ".name"))
         )
  
})

kable(head(churchill_scrape))
```

A practical first question I had was "How many fellowships are given out each year?". Well, now we can see:

```{r message=FALSE, warning=FALSE}
churchill_scrape_saved <- read_csv(here("static", "churchill_scrape.csv"))

churchill_scrape_saved %>%
  count(year) %>%
  ggplot(aes(x = as.numeric(year), y = n)) +
  geom_line() + 
  labs(x = "Year", y = "Number of fellowships funded")

```

So, that's an interesting function. I guess the number of fellowships given out each year is the result of lots of different factors. Some of them will come and go abruptly. There could be a decision made by the trust to spend a lot more money such as in 2002 or not having as much from interest in the trust such as in 2009 and 2010.

But back to the main question: where do they go?

The *places* visited are part of the string contained in `churchill_scrape$project`. So, with a bit of regex I pulled the *places* out.

```{r message=FALSE, warning=FALSE}
churchill_regions <- churchill_scrape_saved %>%
  mutate(region = str_extract(project, "(?<= - )(.*)(?=\n)")) %>%
  mutate(region = str_split(region, ",")) %>%
  unnest(region) %>%
  mutate(region = str_trim(region)) %>%
  mutate(region = str_replace_all(region, "[.]", "")) %>%
  filter(is.na(region) == FALSE)


  kable(head(churchill_regions))
```

Now, let's just hit pause on the "scrapy scrapy data data wooooo" process and take the time to remember two things.

1) Asking a question with data involves applying *definitions* which should be made explicit
2) This is real data and so will contain errors

Definitions are important because they allow us to agregate information systematically. But definitions also make value judgements. Definitions don't come from the data, they are imposed on the data. They reflect our thinking about where the data came from and influence our thinking about the data after the analyses are done.

In this case, the question "where do they go?" lends itself to be answered with a list of *countries*. But *country* is a notoriourly dificult construct to define. Labeling, or not labeling, a geographic region as a country carries great policial meaning. And, with a read through the Churchill website, it seems that that several fellows have visited *places* that under some definitions would be countries but under other definitions would not be.

So, I decided to use a definition that was consistent with my original question. I wanted to see (visually) where fellows went. Since this was always going to end up being mapped I decided to manually change the *places* visited to be *regions* in the `maps::world` package.

This also allowed me to take care of the errors. I built a `tibble` with the regions that were on the map and checked if the places in each fellowship were listed. If they weren't then I manually changed them based on my best estiamte of where they actually visited.

```{r message=FALSE, warning=FALSE}
map_regions <- map_data("world") %>%
  select(region) %>%
  distinct()

churchill_regions_map <- churchill_regions %>%
  mutate(match = if_else(region %in% pull(map_regions, region), "yes", "no"))
```

So then I reimported the manually corrected file.

```{r message=FALSE, warning=FALSE}
churchill_regions_map_corrected <- read_csv(here("static", "churchill_regions_map_corrected.csv")) %>%
  filter(is.na(corrected) == FALSE)

kable(head(churchill_regions_map_corrected))
```

Which means that we can finally see which regions of the world are most visited by Churchill Fellows.

```{r message=FALSE, warning=FALSE}
churchill_regions_map_corrected %>%
  count(corrected) %>%
  top_n(10) %>%
  ggplot(aes(x = reorder(corrected, n), y = n)) + 
  geom_col() + 
  labs(x = "Places visited", y = "Number of times visited", title = "Most visited palces by Churchill fellows from 1966 to 2018") + 
  coord_flip()

```

So, North America and Europe really dominate the most visited regions. To see the extent of visits across the world it might make more sense to view the number of visits to each reagion on a map.

```{r message=FALSE, warning=FALSE}
count_regions <- churchill_regions_map_corrected %>%
  count(corrected)

world_map <- map_data("world") %>%
  left_join(count_regions, by = c("region" = "corrected"))

ggplot(world_map, aes(map_id = region, fill = n))+
  geom_map(map = world_map,  color = "white")+
  expand_limits(x = world_map$long, y = world_map$lat)+
  scale_fill_viridis_c(option = "C", trans = "log") + 
  labs(fill = "Number of visits (log)") + 
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())
```

It really shows where Australians think they can go to learn something. And where they don't think they can learn anything. Its really telling that west Africa and central Asia are so unvisited. In fact, this is a really bad failure. It means that the sort of ideas that fellows bring back to Australia are the same ones, from the same sorts of people and the same sorts of places.

So what places are changing their share of visits from fellows? Within each decade, to put the number of visits to each region in contect it would help to look at the number of visits as a percentage of the number of awards given out.

```{r message=FALSE, warning=FALSE}
churchill_decades_awards <- churchill_scrape_saved %>%
  mutate(decade = year %/% 10 * 10) %>%
  count(decade) %>%
  rename(awards_this_decade = n)

churchill_decades_visited <- churchill_regions_map_corrected %>%
  mutate(decade = year %/% 10 * 10) %>%
  count(corrected, decade) %>%
  rename(visits_this_place_this_decade = n) %>%
  complete(corrected, decade, fill = list(visits_this_place_this_decade = 0)) %>%
  left_join(churchill_decades_awards, by = "decade") %>%
  mutate(percent_of_awards_visited_this_region_this_decade = visits_this_place_this_decade *100 / awards_this_decade) %>%
  group_by(corrected) %>%
  filter(sum(visits_this_place_this_decade) > 25) %>%
  ungroup()

```

This lets us look and see which were the most visited places each decade as a percentage of the number of fellowships given out each year.

```{r message=FALSE, warning=FALSE}

churchill_decades_visited %>%
  group_by(decade) %>%
  top_n(6, percent_of_awards_visited_this_region_this_decade) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(corrected, percent_of_awards_visited_this_region_this_decade) , y = percent_of_awards_visited_this_region_this_decade, fill = decade)) +
  geom_col() + 
  coord_flip() + 
  facet_wrap(~ decade) + 
  guides(fill = NULL) + 
  labs(y = "Percent of awards visiting each place each decade", fill = "Decade", x = "")

```

This looks pretty stable pattern across the decades. The top three of the USA, UK and Canada are the most visited places in all six decades that the Churchill Fellowship has been awarded.

To look at this in a more principled manner, we can identify trends in the patterns of fellows' visiting behaviour across the decades by fitting some models using `glm`.

```{r message=FALSE, warning=FALSE}

slopes <- churchill_decades_visited %>%
    nest(-corrected) %>%
    mutate(models = purrr::map(data, ~ glm(cbind(visits_this_place_this_decade, (awards_this_decade - visits_this_place_this_decade)) ~ decade, ., family = "binomial"))) %>%
    unnest(purrr::map(models, tidy)) %>%
    filter(term == "decade") %>%
    mutate(p.value = p.adjust(p.value))
```

This lets us look at the places that exhibited the biggest positive change in the number of visits per fellowships awarded in each decade.

```{r message=FALSE, warning=FALSE}
slopes %>%
  filter(p.value < .05) %>%
  top_n(6, estimate) %>% 
  inner_join(churchill_decades_visited) %>%
  ggplot(aes(decade, percent_of_awards_visited_this_region_this_decade)) + 
  geom_point() +
  geom_smooth() +
  facet_wrap(~ corrected, scales = "free") +
  labs(x = "Decade", y = "Percentage of awards each decade that visited this place")

```

And look at the places with the greatest negative change in visits per fellowships given each decade.

```{r message=FALSE, warning=FALSE}
slopes %>%
  filter(p.value < .05) %>%
  top_n(6, -estimate) %>% 
  inner_join(churchill_decades_visited) %>%
  ggplot(aes(decade, percent_of_awards_visited_this_region_this_decade)) + 
  geom_point() +
  geom_smooth() +
  facet_wrap(~ corrected, scales = "free") +
  labs(x = "Decade", y = "Percentage of awards each decade that visited this place")

```

Ireland is the stand out mover. Its gone from attracting less than 1% of fellows in the 1960's to more than 8% of fellows so far this decade.

Finally, one of the interesting things about the fellowship is visiting multiple places. So, it might be interesting to see which combinations of places fellows visit the most. This is a job for the `UpSetR` package.

```{r message=FALSE, warning=FALSE}

wtf <- churchill_regions_map_corrected %>%
  select(project, corrected) %>%
  mutate(n = 1) %>%
  distinct() %>%
  spread(corrected, n) %>%
  select(-project) %>%
  replace(is.na(.), 0)

upset(as.data.frame(wtf), order.by = "freq", nsets = 10)
```

So, not only are the USA and UK the most visited places, but that combination is the most frequently visited combiantion of places!